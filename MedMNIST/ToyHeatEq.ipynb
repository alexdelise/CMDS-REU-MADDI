{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf557f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1a7e7",
   "metadata": {},
   "source": [
    "### Data and Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34855994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_Stuff(n, m, numSamples, device, alpha):\n",
    "    X_lin = torch.linspace(-6, 6, steps=min(m, n), device=device)\n",
    "    sigmoid_flipped = torch.exp(X_lin) / (1 + torch.exp(X_lin)) \n",
    "    singular_values = 10 ** (-alpha * sigmoid_flipped)\n",
    "    Sigma_X = torch.diag(singular_values)\n",
    "\n",
    "    k = min(m, n)\n",
    "    data = torch.randn(n, k, device=device)\n",
    "    Q, _ = torch.linalg.qr(data)\n",
    "    U = Q[:, :k]\n",
    "    GammaX = U @ Sigma_X @ U.T\n",
    "    Sigma_X_sqrt = torch.diag(torch.sqrt(torch.diag(Sigma_X)))\n",
    "    L_X = U @ Sigma_X_sqrt\n",
    "\n",
    "    mu_X = torch.zeros(n, 1, device=device)\n",
    "    Z = torch.randn(k, numSamples, device=device)\n",
    "    X = mu_X + L_X @ Z\n",
    "    return X, GammaX, L_X\n",
    "\n",
    "def E_Stuff(m, numSamples, noiseSigma, device):\n",
    "    GammaE = noiseSigma**2 * torch.eye(m, device=device)\n",
    "    L_E = torch.linalg.cholesky(GammaE)\n",
    "    E = L_E @ torch.randn(m, numSamples, device=device)\n",
    "    return E, GammaE, L_E\n",
    "\n",
    "def heateq(n: int, kappa: float = 1.0, dx: float = 1.0, device=None):\n",
    "    device = device or torch.device('cpu')\n",
    "    e = torch.ones(n, device=device)\n",
    "    diagonals = [-2 * e, e[:-1], e[:-1]]\n",
    "    L = torch.diag(diagonals[0]) + torch.diag(diagonals[1], diagonal=1) + torch.diag(diagonals[2], diagonal=-1)\n",
    "    return kappa * L / dx**2\n",
    "\n",
    "def Y_Stuff(X, GammaX, E, GammaE, F):\n",
    "    Y = F @ X + E\n",
    "    GammaY = F @ GammaX @ F.T + GammaE\n",
    "    L_Y = torch.linalg.cholesky(GammaY)\n",
    "    return Y, GammaY, L_Y\n",
    "\n",
    "def forwardOpt(F, L_X, r):\n",
    "    Cf = F @ L_X\n",
    "    Uf, Sf, Vhf = torch.linalg.svd(Cf)\n",
    "    Cr = Uf[:, :r] @ torch.diag(Sf[:r]) @ Vhf[:r, :]\n",
    "    return Cr @ torch.linalg.pinv(L_X)\n",
    "\n",
    "def inverseOpt(F, GammaX, L_Y, r):\n",
    "    C_i = GammaX @ F.T @ torch.linalg.pinv(L_Y.T)\n",
    "    U_i, S_i, Vh_i = torch.linalg.svd(C_i)\n",
    "    U_r_i, S_r_i, Vh_r_i = U_i[:, :r], torch.diag(S_i[:r]), Vh_i[:r, :]\n",
    "    C_r_i = U_r_i @ S_r_i @ Vh_r_i\n",
    "    M_r_i = C_r_i @ torch.linalg.pinv(L_Y)\n",
    "    return M_r_i\n",
    "\n",
    "def forwardCases(Ahat, F, L_X, X, Y, r):\n",
    "    k   = torch.linalg.matrix_rank(L_X).item()\n",
    "    ell = torch.linalg.matrix_rank(F).item()\n",
    "    m, n = F.shape\n",
    "    p   = min(m, n)\n",
    "\n",
    "\n",
    "    print(f\"rank(L_X) = {k}  — {'full' if k == n else 'deficient'}\")\n",
    "    print(f\"rank(F)   = {ell} — {'full' if ell == p else 'deficient'}\")\n",
    "\n",
    "    U, S, Vh = torch.linalg.svd(L_X, full_matrices=False)\n",
    "    Uk, Sk, Vhk = U[:, :k], torch.diag(S[:k]), Vh[:k, :]\n",
    "    Proj = Uk @ Uk.T\n",
    "\n",
    "    Cf = F @ L_X\n",
    "    Uf, Sf, Vhf = torch.linalg.svd(Cf)\n",
    "    Cr = Uf[:, :r] @ torch.diag(Sf[:r]) @ Vhf[:r, :]\n",
    "\n",
    "    if k == n and ell == p:  # Case 1\n",
    "        print(\"\\nCase 1: k = n, ℓ = p\")\n",
    "        if r >= n:\n",
    "            err = torch.mean(torch.abs(Ahat - F))\n",
    "            print(f\"MAE: |Â - F| = {err:.3f}\")\n",
    "        else:\n",
    "            err = torch.mean(torch.abs(Ahat - Cr @ torch.linalg.pinv(L_X)))\n",
    "            print(f\"MAE: |Â - (FL_X)_r L_X†| = {err:.3f}\")\n",
    "\n",
    "    elif k == n and ell < p:  # Case 2\n",
    "        print(\"\\nCase 2: k = n, ℓ < p\")\n",
    "        if r >= ell:\n",
    "            err = torch.mean(torch.abs(Ahat - F))\n",
    "            print(f\"MAE: |Â - F| = {err:.3f}\")\n",
    "        else:\n",
    "            err = torch.mean(torch.abs(Ahat - Cr @ torch.linalg.pinv(L_X)))\n",
    "            print(f\"MAE: |Â - (FL_X)_r L_X†| = {err:.3f}\")\n",
    "\n",
    "    elif k < n and ell == p:  # Case 3\n",
    "        print(\"\\nCase 3: k < n, ℓ = p\")\n",
    "        if r >= min(k, ell):\n",
    "            err = torch.mean(torch.abs(Ahat - F @ Proj))\n",
    "            print(f\"MAE: |Â - F U_kU_kᵀ| = {err:.3f}\")\n",
    "        else:\n",
    "            err = torch.mean(torch.abs(Ahat - Cr @ torch.linalg.pinv(L_X)))\n",
    "            print(f\"MAE: |Â - (FL_X)_r L_X†| = {err:.3f}\")\n",
    "\n",
    "    else:  # Case 4\n",
    "        print(\"\\nCase 4: k < n, ℓ < p\")\n",
    "        if r >= min(k, ell):\n",
    "            err = torch.mean(torch.abs(Ahat - F @ Proj))\n",
    "            print(f\"MAE: |Â - F U_kU_kᵀ| = {err:.3f}\")\n",
    "        else:\n",
    "            err = torch.mean(torch.abs(Ahat - Cr @ torch.linalg.pinv(L_X)))\n",
    "            print(f\"MAE: |Â - (FL_X)_r L_X†| = {err:.3f}\")\n",
    "\n",
    "    data_err = torch.mean(torch.abs(Ahat @ X - Y))\n",
    "    print(f\"MAE: |ÂX - Y| = {data_err:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cd303",
   "metadata": {},
   "source": [
    "# Forward Rank Scenarios of $\\mathbf{F}$ and $\\mathbf{L}_X$\n",
    "- $p = \\min \\{m, n\\}$\n",
    "- $\\operatorname{rank}(\\mathbf{F}) = \\ell$\n",
    "- $\\operatorname{rank}(\\mathbf{L}_X) = k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d84a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank(L_X) = 1000  — full\n",
      "rank(F)   = 994 — deficient\n",
      "\n",
      "Case 2: k = n, ℓ < p\n",
      "MAE: |Â - (FL_X)_r L_X†| = 0.000\n",
      "MAE: |ÂX - Y| = 0.042\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "m = 1000\n",
    "numSamples = n\n",
    "alpha = 5 # lower number helps keep L_X full rank\n",
    "noiseSigma = 0.05\n",
    "r = 500\n",
    "\n",
    "# Setup matrices\n",
    "F = heateq(n=n, device=device)\n",
    "X, GammaX, L_X = X_Stuff(n, m, numSamples, device, alpha)\n",
    "E, GammaE, L_E = E_Stuff(m, numSamples, noiseSigma, device)\n",
    "Y, GammaY, L_Y = Y_Stuff(X, GammaX, E, GammaE, F)\n",
    "\n",
    "# Rank summary\n",
    "rankF = torch.linalg.matrix_rank(F).item()\n",
    "rankLX = torch.linalg.matrix_rank(L_X).item()\n",
    "rankFLX = torch.linalg.matrix_rank(F @ L_X).item()\n",
    "p = min(m, n)\n",
    "k = rankLX\n",
    "ell = rankF\n",
    "\n",
    "# Print case\n",
    "Ahat = forwardOpt(F, L_X, r)\n",
    "forwardCases(Ahat, F, L_X, X, Y, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8825d",
   "metadata": {},
   "source": [
    "# Learned vs. Optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f240c17",
   "metadata": {},
   "source": [
    "### ED Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc926222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# class LinearAutoencoder(nn.Module):\n",
    "#     def __init__(self, input_dim, bottleneck_dim):\n",
    "#         super().__init__()\n",
    "#         self.encoder = nn.Linear(input_dim, bottleneck_dim, bias=False)\n",
    "#         self.decoder = nn.Linear(bottleneck_dim, input_dim, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.decoder(self.encoder(x))\n",
    "\n",
    "# # Move training data to the correct device\n",
    "# X_device = X.to(device)\n",
    "# Y_device = Y.to(device)\n",
    "\n",
    "# # Train forward autoencoder (X → Y)\n",
    "# model_f = LinearAutoencoder(input_dim=m, bottleneck_dim=r).to(device)\n",
    "# opt_f = optim.Adam(model_f.parameters(), lr=1e-3)\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "# for _ in range(200):\n",
    "#     model_f.train()\n",
    "#     opt_f.zero_grad()\n",
    "#     loss = loss_fn(model_f(X_device.T), Y_device.T)\n",
    "#     loss.backward()\n",
    "#     opt_f.step()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     A_learned_f = model_f.decoder.weight @ model_f.encoder.weight\n",
    "\n",
    "# # Train inverse autoencoder (Y → X)\n",
    "# model_i = LinearAutoencoder(input_dim=m, bottleneck_dim=r).to(device)\n",
    "# opt_i = optim.Adam(model_i.parameters(), lr=1e-3)\n",
    "\n",
    "# for _ in range(200):\n",
    "#     model_i.train()\n",
    "#     opt_i.zero_grad()\n",
    "#     loss = loss_fn(model_i(Y_device.T), X_device.T)\n",
    "#     loss.backward()\n",
    "#     opt_i.step()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     A_learned_i = model_i.decoder.weight @ model_i.encoder.weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322fcca",
   "metadata": {},
   "source": [
    "### Rank Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11053316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks = list(range(25, n - 24, 25))\n",
    "# num_epochs = 200\n",
    "# lr = 1e-3\n",
    "\n",
    "# # Prepare results storage\n",
    "# results = {\n",
    "#     'forward': {'theory': [], 'learned': []},\n",
    "#     'inverse': {'theory': [], 'learned': []}\n",
    "# }\n",
    "\n",
    "# # Precompute SVDs of theoretical operators\n",
    "# # Forward operator SVD\n",
    "# C_f = F @ L_X\n",
    "# U_f, S_f, Vh_f = torch.linalg.svd(C_f)\n",
    "\n",
    "# # Inverse operator SVD\n",
    "# C_i = GammaX @ F.T @ torch.linalg.pinv(L_Y.T)\n",
    "# U_i, S_i, Vh_i = torch.linalg.svd(C_i)\n",
    "\n",
    "# # Loop over ranks\n",
    "# for r in ranks:\n",
    "#     if r % 100 == 0: print(f\"On Rank {r}\")\n",
    "    \n",
    "#     # --- Forward Case ---\n",
    "#     # Truncate SVD\n",
    "#     U_r_f = U_f[:, :r]\n",
    "#     S_r_f = torch.diag(S_f[:r])\n",
    "#     Vh_r_f = Vh_f[:r, :]\n",
    "#     C_r_f = U_r_f @ S_r_f @ Vh_r_f\n",
    "    \n",
    "#     # Optimal forward mapping\n",
    "#     M_r_f = C_r_f @ torch.linalg.pinv(L_X)\n",
    "#     diffs_opt_f = M_r_f @ X_device - Y_device\n",
    "#     results['forward']['theory'].append(torch.norm(diffs_opt_f, dim=0).mean().item())\n",
    "\n",
    "#     # Train forward autoencoder\n",
    "#     ae_f = LinearAutoencoder(m, r).to(device)\n",
    "#     opt_f = optim.Adam(ae_f.parameters(), lr=lr)\n",
    "#     loss_fn = nn.MSELoss()\n",
    "#     for _ in range(num_epochs):\n",
    "#         opt_f.zero_grad()\n",
    "#         out_f = ae_f(X_device.T)\n",
    "#         loss = loss_fn(out_f, Y_device.T)\n",
    "#         loss.backward()\n",
    "#         opt_f.step()\n",
    "#     with torch.no_grad():\n",
    "#         A_f = ae_f.decoder.weight @ ae_f.encoder.weight\n",
    "#         diffs_learn_f = A_f @ X_device - Y_device\n",
    "#         results['forward']['learned'].append(torch.norm(diffs_learn_f, dim=0).mean().item())\n",
    "\n",
    "#     # --- Inverse Case ---\n",
    "#     # Truncate SVD\n",
    "#     U_r_i = U_i[:, :r]\n",
    "#     S_r_i = torch.diag(S_i[:r])\n",
    "#     Vh_r_i = Vh_i[:r, :]\n",
    "#     C_r_i = U_r_i @ S_r_i @ Vh_r_i\n",
    "    \n",
    "#     # Optimal inverse mapping\n",
    "#     M_r_i = C_r_i @ torch.linalg.pinv(L_Y)\n",
    "#     diffs_opt_i = M_r_i @ Y_device - X_device\n",
    "#     results['inverse']['theory'].append(torch.norm(diffs_opt_i, dim=0).mean().item())\n",
    "\n",
    "#     # Train inverse autoencoder\n",
    "#     ae_i = LinearAutoencoder(m, r).to(device)\n",
    "#     opt_i = optim.Adam(ae_i.parameters(), lr=lr)\n",
    "#     for _ in range(num_epochs):\n",
    "#         opt_i.zero_grad()\n",
    "#         out_i = ae_i(Y_device.T)\n",
    "#         loss = loss_fn(out_i, X_device.T)\n",
    "#         loss.backward()\n",
    "#         opt_i.step()\n",
    "#     with torch.no_grad():\n",
    "#         A_i = ae_i.decoder.weight @ ae_i.encoder.weight\n",
    "#         diffs_learn_i = A_i @ Y_device - X_device\n",
    "#         results['inverse']['learned'].append(torch.norm(diffs_learn_i, dim=0).mean().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87e277",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7486a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pastel‑Everforest colours \n",
    "# ef_pastel   = ['#a7c080', '#d3869b', \"#83c0c0\", '#e69875', '#a988b0', \"#b8912f\"]\n",
    "# line_styles = {'theory': '-',  'learned': '--'}\n",
    "# markers     = {'theory': 'o',  'learned': 's'}\n",
    "# lw, ms      = 1.5, 4\n",
    "\n",
    "# # combined forward/inverse plot\n",
    "# plt.figure(figsize=(7.8, 4.7))\n",
    "# modes = ['forward', 'inverse']\n",
    "# short_label = {'theory': 'O', 'learned': 'L'}\n",
    "\n",
    "# for i, mode in enumerate(modes):\n",
    "#     col = ef_pastel[i]\n",
    "#     for kind in ('theory', 'learned'):\n",
    "#         plt.plot(\n",
    "#             ranks,\n",
    "#             results[mode][kind],\n",
    "#             line_styles[kind],\n",
    "#             marker=markers[kind],\n",
    "#             color=col,\n",
    "#             lw=lw,\n",
    "#             ms=ms,\n",
    "#             label=f\"{mode.capitalize()} ({short_label[kind]})\"\n",
    "#         )\n",
    "\n",
    "# plt.xlabel('Rank $r$')\n",
    "# plt.ylabel(r'Average $\\ell_2$ Reconstruction Error')\n",
    "# plt.yscale('log')\n",
    "# plt.legend(ncol=2, fontsize='small')\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"synthetic_forward_inverse_ranksweep.png\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
