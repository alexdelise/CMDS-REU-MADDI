{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, GaussianBlur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# MedMNIST import\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MedMNIST Data setup ---\n",
    "data_flag = 'chestmnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "train_dataset = DataClass(split='train', download=True)\n",
    "numSamples = len(train_dataset)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data tensors --------------------------------------------------------\n",
    "def _get_tensor(ds, n):\n",
    "    \"\"\"Stack first n samples, convert to float32 in [0,1].\"\"\"\n",
    "    imgs = []\n",
    "    for i in range(n):\n",
    "        x, _ = ds[i]\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            t = x.float() / 255.0\n",
    "        elif isinstance(x, np.ndarray):\n",
    "            t = torch.from_numpy(x).float() / 255.0\n",
    "            if t.ndim == 3:\n",
    "                t = t.permute(2, 0, 1)\n",
    "        else:\n",
    "            t = TF.to_tensor(x)\n",
    "        imgs.append(t[0])\n",
    "    return torch.stack(imgs).to(device)\n",
    "\n",
    "# Prepare dataset\n",
    "X_raw = _get_tensor(train_dataset, numSamples) \n",
    "dim = X_raw[0].numel()  # 28*28 = 784\n",
    "r = 25  # bottleneck / testing rank\n",
    "\n",
    "# X Stuff\n",
    "X = X_raw.view(numSamples, -1).T\n",
    "gammaX = (1/numSamples) * X @ X.T + 1e-5 * torch.eye(dim, device=device)\n",
    "L_X = torch.linalg.cholesky(gammaX)\n",
    "\n",
    "# F Stuff\n",
    "blurKernelSizeF = 5\n",
    "blurSigmaF = 1.0\n",
    "forwardBlur = GaussianBlur(kernel_size=blurKernelSizeF, sigma=blurSigmaF)\n",
    "basisImages = torch.eye(dim).reshape(dim, 1, 28, 28)\n",
    "F_cols = []\n",
    "for j in range(dim):\n",
    "    F_cols.append(forwardBlur(basisImages[j]).flatten())\n",
    "F = torch.stack(F_cols, dim=1).to(device)\n",
    "FX = F @ X\n",
    "\n",
    "# E Stuff\n",
    "noiseSigma = 0.05\n",
    "E = torch.randn_like(FX) * noiseSigma\n",
    "gammaE = noiseSigma**2 * torch.eye(dim, device=device)\n",
    "\n",
    "# Y Stuff\n",
    "Y = FX + E\n",
    "gammaY = F @ gammaX @ F.T + gammaE + 1e-5 * torch.eye(dim, device=device)\n",
    "L_Y = torch.linalg.cholesky(gammaY)\n",
    "\n",
    "\n",
    "# Theoretical Optimizer\n",
    "C = F @ L_X\n",
    "U, S, Vh = torch.linalg.svd(C)\n",
    "U_r, S_r, Vh_r = U[:, :r], torch.diag(S[:r]), Vh[:r, :]\n",
    "C_r = U_r @ S_r @ Vh_r\n",
    "M_r = C_r @ torch.linalg.pinv(L_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216af7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# random training-set index\n",
    "idx = 7181\n",
    "\n",
    "# (i) original image  →  (H,W)\n",
    "orig_img = X_raw[idx].cpu()\n",
    "if orig_img.ndim == 3:     \n",
    "    orig_img = orig_img[0]\n",
    "\n",
    "# (ii) blurred image  F \\bar{X}\n",
    "blur_img = forwardBlur(orig_img.unsqueeze(0)).squeeze(0).cpu()\n",
    "\n",
    "# (iii) blurred + noise image  F \\bar{X} + E\n",
    "noise            = torch.randn_like(blur_img) * noiseSigma\n",
    "blur_noise_img   = (blur_img + noise).clamp(0, 1).cpu()\n",
    "\n",
    "# ── plot & save \n",
    "fig, axes = plt.subplots(1, 3, figsize=(7.5, 2.7))\n",
    "axes[0].imshow(orig_img,        cmap='gray')\n",
    "axes[0].set_title(r'Original $\\mathbf{x}$')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(blur_img,        cmap='gray')\n",
    "axes[1].set_title(r'Blurred $\\mathbf{F} \\mathbf{x}$')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(blur_noise_img,  cmap='gray')\n",
    "axes[2].set_title(r'Observation $\\mathbf{y} = \\mathbf{F} \\mathbf{x} + \\varepsilon$')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "out_dir = f\"E2EForward/MedMNIST/Pics\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "plt.savefig(f\"{out_dir}/{data_flag}_mapping{idx}_{r}.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Autoencoder setup \n",
    "batch_size = 128\n",
    "num_epochs = 200\n",
    "\n",
    "X_tensor = X.clone().to(torch.float32)\n",
    "Y_tensor = Y.clone().to(torch.float32)\n",
    "\n",
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, bottleneck_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_dim, bottleneck_dim, bias=False)\n",
    "        self.decoder = nn.Linear(bottleneck_dim, input_dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "model     = LinearAutoencoder(input_dim=dim, bottleneck_dim=r).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop using average per-sample L2 error\n",
    "train_errors = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X.T)\n",
    "    target  = Y.T\n",
    "\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate average per-sample l2 error\n",
    "    with torch.no_grad():\n",
    "        A_learned = model.decoder.weight @ model.encoder.weight\n",
    "        diffs = A_learned @ X - Y\n",
    "        avg_l2_err = torch.norm(diffs, dim=0).mean().item()\n",
    "        train_errors.append(avg_l2_err)\n",
    "\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "idx = 7181\n",
    "\n",
    "orig_img   = X_raw[idx].view(28, 28).cpu()\n",
    "y_img      = Y[:, idx].view(28, 28).cpu()\n",
    "opt_img    = (M_r @ X)[:, idx].view(28, 28).cpu()\n",
    "learn_img  = (A_learned @ X)[:, idx].view(28, 28).cpu()\n",
    "\n",
    "err_opt   = torch.abs(opt_img   - y_img)\n",
    "err_learn = torch.abs(learn_img - y_img)\n",
    "err_vmin, err_vmax = 0.0, max(err_opt.max(), err_learn.max()).item()\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4.2))\n",
    "gs  = gridspec.GridSpec(\n",
    "    2, 4,\n",
    "    width_ratios=[1, 1, 1, 0.06],\n",
    "    wspace=0.20, hspace=0.30\n",
    ")\n",
    "\n",
    "# row 0\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.imshow(orig_img, cmap='gray')\n",
    "ax.set_title(r'Original $\\mathbf{x}$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.imshow(opt_img, cmap='gray')\n",
    "ax.set_title(fr'Optimal $\\widehat{{\\mathbf{{A}}}}_{{{r}}} \\mathbf{{x}}$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "im = ax.imshow(err_opt, cmap='inferno', vmin=err_vmin, vmax=err_vmax)\n",
    "ax.set_title(fr'$|\\widehat{{\\mathbf{{A}}}}_{{{r}}} \\mathbf{{x}} - \\mathbf{{y}}|$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "# row 1\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax.imshow(y_img, cmap='gray')\n",
    "ax.set_title(r'Observation $\\mathbf{y}$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 1])\n",
    "ax.imshow(learn_img, cmap='gray')\n",
    "ax.set_title(fr'Learned $\\mathbf{{A}}_{{{r}}} \\mathbf{{x}}$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 2])\n",
    "ax.imshow(err_learn, cmap='inferno', vmin=err_vmin, vmax=err_vmax)\n",
    "ax.set_title(fr'$|\\mathbf{{A}}_{{{r}}} \\mathbf{{x}} - \\mathbf{{y}}|$', pad=4)\n",
    "ax.axis('off')\n",
    "\n",
    "# color-bar\n",
    "cax = fig.add_subplot(gs[:, 3])\n",
    "plt.colorbar(im, cax=cax)\n",
    "cax.yaxis.tick_right()\n",
    "\n",
    "out_dir = f\"E2EForward/MedMNIST/Pics\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "plt.savefig(f\"{out_dir}/e2efor_{data_flag}_mapping{idx}_errorcomparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, torch\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from torchvision.transforms import GaussianBlur\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# where to stash matrices and final plots \n",
    "save_root     = \"E2EForward\"\n",
    "matrices_root = os.path.join(save_root, \"MedMNIST\", \"Matrices\")\n",
    "tests_root    = os.path.join(save_root, \"MedMNIST\", \"Pics\")\n",
    "os.makedirs(matrices_root, exist_ok=True)\n",
    "os.makedirs(tests_root, exist_ok=True)\n",
    "\n",
    "# helper: run rank sweep on ONE MedMNIST subset \n",
    "def run_rank_sweep(data_flag, ranks, train_epochs=350, lr=1e-4):\n",
    "    \"\"\"Return ([theory avg l2], [AE avg l2]) for the given dataset\n",
    "       and store matrices to pickles for every rank.\"\"\"\n",
    "    info = INFO[data_flag]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    train_ds = DataClass(split='train', download=True)\n",
    "\n",
    "    numSamples = len(train_ds)\n",
    "    X_raw = _get_tensor(train_ds, numSamples)\n",
    "    dim = X_raw[0].numel()\n",
    "\n",
    "    X = X_raw.view(numSamples, -1).T\n",
    "    gammaX = (1 / numSamples) * X @ X.T + 1e-5 * torch.eye(dim, device=device)\n",
    "    L_X = torch.linalg.cholesky(gammaX)\n",
    "\n",
    "    blurKernelSizeF = 5\n",
    "    blurSigmaF = 1.0\n",
    "    blur = GaussianBlur(kernel_size=blurKernelSizeF, sigma=blurSigmaF)\n",
    "    basisImages = torch.eye(dim).reshape(dim, 1, 28, 28)\n",
    "    F_cols = [blur(basisImages[j]).flatten() for j in range(dim)]\n",
    "    F = torch.stack(F_cols, dim=1).to(device)\n",
    "\n",
    "    FX = F @ X\n",
    "    noiseSigma = 0.05\n",
    "    E = torch.randn_like(FX) * noiseSigma\n",
    "    Y = FX + E\n",
    "\n",
    "    gammaE = noiseSigma**2 * torch.eye(dim, device=device)\n",
    "    gammaY = F @ gammaX @ F.T + gammaE + 1e-5 * torch.eye(dim, device=device)\n",
    "    #gammaY = (1 / numSamples) * Y @ Y.T #+ 1e-5 * torch.eye(dim, device=device)\n",
    "    L_Y = torch.linalg.cholesky(gammaY)\n",
    "\n",
    "    C = F @ L_X\n",
    "    U, S, Vh = torch.linalg.svd(C)\n",
    "\n",
    "    theory_err, learned_err = [], []\n",
    "    ds_dir = os.path.join(matrices_root, data_flag)\n",
    "    os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "    for r in ranks:\n",
    "        if r % 100 == 0:\n",
    "            print(f\"On Rank {r}\")\n",
    "\n",
    "        U_r = U[:, :r]\n",
    "        S_r = torch.diag(S[:r])\n",
    "        Vh_r = Vh[:r, :]\n",
    "        C_r = U_r @ S_r @ Vh_r\n",
    "        M_r = C_r @ torch.linalg.pinv(L_X)\n",
    "\n",
    "        diffs_opt = M_r @ X - Y\n",
    "        avg_l2_opt = torch.norm(diffs_opt, dim=0).mean().item()\n",
    "        theory_err.append(avg_l2_opt)\n",
    "\n",
    "        ae = LinearAutoencoder(dim, r).to(device)\n",
    "        opt = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for _ in range(train_epochs):\n",
    "            opt.zero_grad()\n",
    "            out = ae(X.T)\n",
    "            loss = criterion(out, Y.T)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            W_enc = ae.encoder.weight.detach().cpu()\n",
    "            W_dec = ae.decoder.weight.detach().cpu()\n",
    "            A = W_dec @ W_enc\n",
    "            diffs_learn = A.to(device) @ X - Y\n",
    "            avg_l2_learn = torch.norm(diffs_learn, dim=0).mean().item()\n",
    "        learned_err.append(avg_l2_learn)\n",
    "\n",
    "        dump_path = os.path.join(ds_dir, f\"rank_{r:03d}.pkl\")\n",
    "        with open(dump_path, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"optimalMatrix\": M_r.cpu(),\n",
    "                    \"encoderWeight\": W_enc,\n",
    "                    \"decoderWeight\": W_dec,\n",
    "                    \"avgL2Optimal\": avg_l2_opt,\n",
    "                    \"avgL2Learned\": avg_l2_learn,\n",
    "                },\n",
    "                f,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL,\n",
    "            )\n",
    "\n",
    "    return theory_err, learned_err\n",
    "\n",
    "# run all requested datasets\n",
    "datasets  = ['tissuemnist', 'chestmnist', 'organamnist', 'retinamnist']\n",
    "ranks     = list(range(25, 776, 25))\n",
    "results   = defaultdict(dict)\n",
    "num_epochs = 200 # define here for training / plot naming\n",
    "\n",
    "for flag in datasets:\n",
    "    print(f\"\\n▶ Running rank sweep for {flag} …\")\n",
    "    th, le = run_rank_sweep(flag, ranks, train_epochs=num_epochs)\n",
    "    results[flag]['theory']  = th\n",
    "    results[flag]['learned'] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pastel-Everforest colours \n",
    "ef_pastel   = ['#a7c080', '#d3869b', \"#83c0c0\", '#e69875', '#a988b0', \"#b8912f\"]\n",
    "line_styles = {'theory': '-',  'learned': '--'}\n",
    "markers     = {'theory': 'o',  'learned': 's'}\n",
    "lw, ms      = 2.5, 4\n",
    "\n",
    "\n",
    "# combined plot\n",
    "plt.figure(figsize=(7.8, 4.7))\n",
    "short_label = {'theory': 'O', 'learned': 'L'}\n",
    "\n",
    "for i, flag in enumerate(datasets):\n",
    "    col = ef_pastel[i % len(ef_pastel)]\n",
    "    for kind in ('theory', 'learned'):\n",
    "        plt.plot(ranks,\n",
    "                 results[flag][kind],\n",
    "                 line_styles[kind],\n",
    "                 #marker=markers[kind],\n",
    "                 color=col,\n",
    "                 lw=lw,\n",
    "                 ms=ms, \n",
    "                 label=f\"{flag} ({short_label[kind]})\")\n",
    "\n",
    "plt.xlabel('Rank $r$')\n",
    "plt.ylabel(r'Average $\\ell_2$ Reconstruction Error')\n",
    "plt.yscale('log')\n",
    "#plt.title('Average $\\ell_2$ Error vs. Rank')\n",
    "plt.legend(ncol=3, fontsize='small')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"E2EForward/MedMNIST/Pics/e2eforward_ranksweep_200ep.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Inspect stored matrices & compare singular values (4 decimals) ─────────\n",
    "#    • Lists datasets / ranks, loads each pickle\n",
    "#    • Computes singular values of\n",
    "#        – Bayes–optimal map  Mr\n",
    "#        – Learned map        A = W_dec @ W_enc\n",
    "#    • Prints top-k singular values (rounded to 4 decimals) and relative ℓ2 error\n",
    "\n",
    "import os, pickle, torch\n",
    "\n",
    "base_dir  = \"E2EForward/MedMNIST/Matrices\"\n",
    "top_k     = 10                              # how many singular values to show\n",
    "torch.set_printoptions(edgeitems=3, linewidth=120, sci_mode=False)\n",
    "\n",
    "for dataset in sorted(os.listdir(base_dir)):\n",
    "    ds_dir = os.path.join(base_dir, dataset)\n",
    "    if not os.path.isdir(ds_dir):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n══════════  {dataset.upper()}  ══════════\")\n",
    "    for fname in sorted(fn for fn in os.listdir(ds_dir) if fn.endswith(\".pkl\")):\n",
    "        rank   = int(fname.split(\"_\")[1].split(\".\")[0])        # rank_050.pkl → 50\n",
    "        fpath  = os.path.join(ds_dir, fname)\n",
    " \n",
    "        # ── load matrices ───────────────────────────────────────────────────\n",
    "        with open(fpath, \"rb\") as f:\n",
    "            mats = pickle.load(f)\n",
    "\n",
    "        Mr   = mats[\"optimalMatrix\"]\n",
    "        Wenc = mats[\"encoderWeight\"]\n",
    "        Wdec = mats[\"decoderWeight\"]\n",
    "        A    = Wdec @ Wenc                                    # learned full map\n",
    "\n",
    "        # ── singular values ────────────────────────────────────────────────\n",
    "        s_opt    = torch.linalg.svdvals(Mr)\n",
    "        s_learn  = torch.linalg.svdvals(A)\n",
    "\n",
    "        rel_err = torch.norm(s_opt - s_learn) / torch.norm(s_opt)\n",
    "\n",
    "        # Round singular values to 4 decimal places for print\n",
    "        s_opt_rounded   = [round(v.item(), 4) for v in s_opt[:top_k]]\n",
    "        s_learn_rounded = [round(v.item(), 4) for v in s_learn[:top_k]]\n",
    "\n",
    "        print(f\"\\n— Rank {rank:3d} —  ({fpath})\")\n",
    "        #print(\"optimalMatrix shape :\", tuple(Mr.shape))\n",
    "        #print(\"encoderWeight shape :\", tuple(Wenc.shape))\n",
    "        #print(\"decoderWeight shape :\", tuple(Wdec.shape))\n",
    "        print(f\"Relative ℓ₂ error on singular values: {rel_err:.3e}\")\n",
    "        print(f\"Top {top_k} σ(M_r):\", s_opt_rounded)\n",
    "        print(f\"Top {top_k} σ(A)  :\", s_learn_rounded)\n",
    "\n",
    "        # Uncomment next lines if you want FULL singular value lists\n",
    "        # print(\"\\nAll σ(M_r):\\n\", s_opt.cpu())\n",
    "        # print(\"\\nAll σ(A):\\n\",   s_learn.cpu())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
